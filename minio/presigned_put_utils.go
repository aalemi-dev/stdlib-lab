package minio

import (
	"context"
	"fmt"
	"math"
	"net/url"
	"sort"
	"strconv"
	"time"

	"github.com/minio/minio-go/v7"
)

// MultipartUploadInfo contains all information needed for a multipart upload.
// This structure holds all the details required for managing and completing a multipart upload,
// including upload identifiers, presigned URLs for each part, and sizing information.
type MultipartUploadInfo struct {
	// UploadID is the unique identifier for the multipart upload provided by MinIO/S3
	UploadID string `json:"uploadId"`

	// ObjectKey is the path and name of the object in the bucket
	ObjectKey string `json:"objectKey"`

	// PresignedUrls is a slice of temporary URLs for uploading each part
	PresignedUrls []string `json:"presignedUrls"`

	// PartNumbers contains the part numbers corresponding to each URL in PresignedUrls
	PartNumbers []int `json:"partNumbers"`

	// ExpiresAt is the Unix timestamp when the presigned URLs will expire
	ExpiresAt int64 `json:"expiresAt"`

	// RecommendedPartSize is the suggested size in bytes for each part for optimal performance
	RecommendedPartSize int64 `json:"recommendedPartSize"`

	// MaxParts is the maximum number of parts allowed for this upload (S3 limit)
	MaxParts int `json:"maxParts"`

	// ContentType is the MIME type of the object being uploaded
	ContentType string `json:"contentType"`

	// TotalSize is the total size of the object in bytes
	TotalSize int64 `json:"totalSize"`
}

// MultipartUpload represents a multipart upload session.
// This interface provides methods to access information about a multipart upload
// while hiding the internal implementation details.
type MultipartUpload interface {
	// GetUploadID returns the unique identifier for this multipart upload
	GetUploadID() string

	// GetObjectKey returns the object key for this upload
	GetObjectKey() string

	// GetPresignedURLs returns all presigned URLs for this upload
	GetPresignedURLs() []string

	// GetPartNumbers returns all part numbers corresponding to the URLs
	GetPartNumbers() []int

	// GetExpiryTimestamp returns the Unix timestamp when this upload expires
	GetExpiryTimestamp() int64

	// GetRecommendedPartSize returns the recommended size for each part in bytes
	GetRecommendedPartSize() int64

	// GetMaxParts returns the maximum number of parts allowed
	GetMaxParts() int

	// GetContentType returns the content type of the object
	GetContentType() string

	// GetTotalSize returns the total size of the object in bytes
	GetTotalSize() int64

	// IsExpired checks if the upload has expired
	IsExpired() bool
}

// multipartUploadImpl is the internal implementation of MultipartUpload interface.
// This struct provides the actual implementation of the MultipartUpload interface
// while keeping the implementation details private.
type multipartUploadImpl struct {
	// info contains all the data for the multipart upload
	info *MultipartUploadInfo
}

// NewMultipartUpload creates a new MultipartUpload from a MultipartUploadInfo.
// This function is internal to the package and wraps the info structure with the interface.
func newMultipartUpload(info *MultipartUploadInfo) MultipartUpload {
	return &multipartUploadImpl{
		info: info,
	}
}

// GetUploadID returns the unique identifier for this multipart upload.
// This ID is generated by the S3/MinIO server and is required for all operations
// related to this specific multipart upload.
func (m *multipartUploadImpl) GetUploadID() string {
	return m.info.UploadID
}

// GetObjectKey returns the object key (path and filename) for this upload.
// This is the full path where the object will be stored in the bucket.
func (m *multipartUploadImpl) GetObjectKey() string {
	return m.info.ObjectKey
}

// GetPresignedURLs returns all presigned URLs for this upload.
// Returns a copy of the URLs to prevent modification of the internal state.
// These URLs can be used to upload individual parts directly from a client.
func (m *multipartUploadImpl) GetPresignedURLs() []string {
	// Return a copy to prevent modification
	result := make([]string, len(m.info.PresignedUrls))
	copy(result, m.info.PresignedUrls)
	return result
}

// GetPartNumbers returns all part numbers corresponding to the URLs.
// Returns a copy of the part numbers to prevent modification of the internal state.
// These numbers are used to identify each part during the completion process.
func (m *multipartUploadImpl) GetPartNumbers() []int {
	// Return a copy to prevent modification
	result := make([]int, len(m.info.PartNumbers))
	copy(result, m.info.PartNumbers)
	return result
}

// GetExpiryTimestamp returns the Unix timestamp when this upload expires.
// After this time, the presigned URLs will no longer be valid for uploading parts.
func (m *multipartUploadImpl) GetExpiryTimestamp() int64 {
	return m.info.ExpiresAt
}

// GetRecommendedPartSize returns the recommended size for each part in bytes.
// Using this size for most parts (except potentially the last one) will result
// in optimal upload performance.
func (m *multipartUploadImpl) GetRecommendedPartSize() int64 {
	return m.info.RecommendedPartSize
}

// GetMaxParts returns the maximum number of parts allowed for this upload.
// This is a limit imposed by the S3 API specification (typically 10,000 parts).
func (m *multipartUploadImpl) GetMaxParts() int {
	return m.info.MaxParts
}

// GetContentType returns the content type (MIME type) of the object.
// This value will be set as the Content-Type metadata for the final object.
func (m *multipartUploadImpl) GetContentType() string {
	return m.info.ContentType
}

// GetTotalSize returns the total size of the object in bytes.
// This is the combined size of all parts that will make up the final object.
func (m *multipartUploadImpl) GetTotalSize() int64 {
	return m.info.TotalSize
}

// IsExpired checks if the upload has expired.
// Returns true if the current time is past the expiration timestamp.
func (m *multipartUploadImpl) IsExpired() bool {
	return time.Now().Unix() > m.info.ExpiresAt
}

// updateUploadConfig updates the UploadConfig with multipart-specific settings.
// This method ensures that the upload configuration has appropriate default values
// if they haven't been explicitly set.
func (m *MinioClient) updateUploadConfig() {
	// Set default values if not provided
	if m.cfg.UploadConfig.MaxObjectSize == 0 {
		m.cfg.UploadConfig.MaxObjectSize = MaxObjectSize
	}

	if m.cfg.UploadConfig.MinPartSize == 0 {
		m.cfg.UploadConfig.MinPartSize = uint64(minPartSizeForUpload) // 5 MiB default
	}

	if m.cfg.UploadConfig.MultipartThreshold == 0 {
		m.cfg.UploadConfig.MultipartThreshold = MultipartThreshold // 50 MiB default
	}
}

// calculateOptimalPartSize determines the best part size and part count for a given file size.
// This method balances between having too many small parts (that increase overhead) and
// having parts that are too large (which reduces parallelism and restarts granularity).
//
// Parameters:
//   - fileSize: Total size of the file to be uploaded in bytes
//
// Returns:
//   - partSize: Recommended size for each part in bytes
//   - partCount: Number of parts needed with the recommended part size
func (m *MinioClient) calculateOptimalPartSize(fileSize int64) (partSize int64, partCount int) {
	// Default to MinIO minimum (5 MiB)
	minPartSize := minPartSizeForUpload
	if m.cfg.UploadConfig.MinPartSize > 0 {
		minPartSize = int64(m.cfg.UploadConfig.MinPartSize) //nolint:gosec
	}

	// If the file is small, use the minimum part size
	if fileSize < 10*minPartSize {
		partSize = minPartSize
		partCount = int(math.Ceil(float64(fileSize) / float64(partSize)))
		return
	}

	// Calculate a part size that divides evenly
	partSize = int64(math.Ceil(float64(fileSize) / float64(minioLimitPartCount)))

	// Round up to the nearest 1 MiB
	partSize = ((partSize + 1024*1024 - 1) / (1024 * 1024)) * (1024 * 1024)

	// Ensure part size is at least the minimum
	if partSize < minPartSize {
		partSize = minPartSize
	}

	// Recalculate part count with the final part size
	partCount = int(math.Ceil(float64(fileSize) / float64(partSize)))

	return
}

// GenerateMultipartUploadURLs initiates a multipart upload and generates all necessary URLs.
// This method prepares everything needed for a client to directly upload multiple parts
// to MinIO/S3 without further server interaction until the upload is complete.
//
// Parameters:
//   - ctx: Context for the operation
//   - objectKey: Path and name of the object in the bucket
//   - fileSize: Total size of the file in bytes
//   - contentType: MIME type of the file (defaults to "application/octet-stream" if empty)
//   - expiry: Optional custom expiration duration for the presigned URLs
//
// Returns:
//   - MultipartUpload: Interface providing access to upload details
//   - error: Any error that occurred during setup
//
// Example:
//
//	upload, err := minioClient.GenerateMultipartUploadURLs(
//	    ctx,
//	    "uploads/myfile.zip",
//	    fileSize,
//	    "application/zip",
//	    2*time.Hour,
//	)
func (m *MinioClient) GenerateMultipartUploadURLs(
	ctx context.Context,
	bucket, objectKey string,
	fileSize int64,
	contentType string,
	expiry ...time.Duration,
) (MultipartUpload, error) {
	// Determine expiry
	expiryDuration := m.cfg.PresignedConfig.ExpiryDuration
	if len(expiry) > 0 && expiry[0] > 0 {
		expiryDuration = expiry[0]
	}

	// Ensure multipart config is set
	m.updateUploadConfig()

	// Check if file size exceeds maximum
	if fileSize > m.cfg.UploadConfig.MaxObjectSize {
		return nil, fmt.Errorf("file size %d exceeds maximum allowed size %d", fileSize, m.cfg.UploadConfig.MaxObjectSize)
	}

	// Calculate optimal part size and count
	partSize, partCount := m.calculateOptimalPartSize(fileSize)

	// Initiate multipart upload
	if contentType == "" {
		if m.cfg.UploadConfig.DefaultContentType != "" {
			contentType = m.cfg.UploadConfig.DefaultContentType
		} else {
			contentType = UploadDefaultContentType
		}
	}

	uploadID, err := m.initiateMultipartUpload(ctx, bucket, objectKey, contentType)
	if err != nil {
		return nil, fmt.Errorf("failed to initiate multipart upload: %w", err)
	}

	// Generate presigned URLs for each part
	presignedUrls := make([]string, partCount)
	partNumbers := make([]int, partCount)

	for i := 0; i < partCount; i++ {
		partNumber := i + 1
		presignedURL, err := m.generatePartPresignedURL(ctx, bucket, objectKey, uploadID, partNumber, expiryDuration)
		if err != nil {
			// Try to abort the upload if we fail to generate URLs
			_ = m.AbortMultipartUpload(ctx, bucket, objectKey, uploadID)
			return nil, fmt.Errorf("failed to generate presigned URL for part %d: %w", partNumber, err)
		}

		presignedUrls[i] = presignedURL
		partNumbers[i] = partNumber
	}

	// Calculate expiration time
	expiresAt := time.Now().Add(expiryDuration).Unix()

	// Create the internal struct
	info := &MultipartUploadInfo{
		UploadID:            uploadID,
		ObjectKey:           objectKey,
		PresignedUrls:       presignedUrls,
		PartNumbers:         partNumbers,
		ExpiresAt:           expiresAt,
		RecommendedPartSize: partSize,
		MaxParts:            int(minioLimitPartCount), // Fixed by S3 spec
		ContentType:         contentType,
		TotalSize:           fileSize,
	}

	// Wrap with the interface implementation
	return newMultipartUpload(info), nil
}

// initiateMultipartUpload starts a new multipart upload and returns the upload ID.
// This internal method communicates with MinIO/S3 to initialize a multipart upload session.
//
// Parameters:
//   - ctx: Context for the operation
//   - bucket: Name of the bucket
//   - objectKey: Path and name of the object in the bucket
//   - contentType: MIME type of the file
//
// Returns:
//   - string: The upload ID assigned by MinIO/S3
//   - error: Any error that occurred during initialization
func (m *MinioClient) initiateMultipartUpload(ctx context.Context, bucket, objectKey, contentType string) (string, error) {
	core := m.coreClient.Load()
	if core == nil {
		return "", ErrConnectionFailed
	}

	if contentType == "" {
		contentType = "application/octet-stream"
	}

	// Extract tracing information from context or generate new IDs
	traceMetadata := extractTraceMetadataFromContext(ctx)

	// Use a standard client to start multipart upload
	opts := minio.PutObjectOptions{
		ContentType:  contentType,
		UserMetadata: traceMetadata,
	}

	uploadID, err := core.NewMultipartUpload(ctx, bucket, objectKey, opts)
	if err != nil {
		return "", fmt.Errorf("failed to initialize multipart upload: %w", err)
	}

	return uploadID, nil
}

// generatePartPresignedURL creates a presigned URL for uploading a specific part.
// This internal method generates a temporary URL that allows a client to upload
// a part directly to MinIO/S3 without additional authentication.
//
// Parameters:
//   - ctx: Context for the operation
//   - objectKey: Path and name of the object in the bucket
//   - uploadID: The upload ID for the multipart upload
//   - partNumber: The part number (1-10000)
//   - expiry: How long the URL should remain valid
//
// Returns:
//   - string: The presigned URL for uploading the part
//   - error: Any error that occurred during URL generation
func (m *MinioClient) generatePartPresignedURL(ctx context.Context, bucket, objectKey, uploadID string, partNumber int, expiry time.Duration) (string, error) {
	c := m.client.Load()
	if c == nil {
		return "", ErrConnectionFailed
	}

	// Create request parameters for part upload
	reqParams := make(url.Values)
	reqParams.Set("partNumber", strconv.Itoa(partNumber))
	reqParams.Set("uploadId", uploadID)

	// Use Presign method for more control over the request
	presignedURL, err := c.Presign(ctx, "PUT", bucket, objectKey, expiry, reqParams)
	if err != nil {
		return "", fmt.Errorf("failed to generate presigned URL for part %d: %w", partNumber, err)
	}

	// Apply base URL override if configured
	finalURL := presignedURL.String()
	if m.cfg.PresignedConfig.BaseURL != "" {
		finalURL, err = urlGenerator(presignedURL, m.cfg.PresignedConfig.BaseURL)
		if err != nil {
			return "", err
		}
	}

	return finalURL, nil
}

// AbortMultipartUpload aborts a multipart upload.
// This method cancels an in-progress multipart upload and removes any parts
// that have already been uploaded.
//
// Parameters:
//   - ctx: Context for the operation
//   - objectKey: Path and name of the object in the bucket
//   - uploadID: The upload ID to abort
//
// Returns an error if the abort operation fails.
//
// Example:
//
//	err := minioClient.AbortMultipartUpload(ctx, "uploads/myfile.zip", uploadID)
func (m *MinioClient) AbortMultipartUpload(ctx context.Context, bucket, objectKey, uploadID string) error {
	core := m.coreClient.Load()
	if core == nil {
		return ErrConnectionFailed
	}

	err := core.AbortMultipartUpload(ctx, bucket, objectKey, uploadID)
	if err != nil {
		return fmt.Errorf("failed to abort multipart upload: %w", err)
	}

	return nil
}

// CompleteMultipartUpload finalizes a multipart upload by combining all parts.
// This method tells MinIO/S3 to assemble all the uploaded parts into the final object.
//
// Parameters:
//   - ctx: Context for the operation
//   - objectKey: Path and name of the object in the bucket
//   - uploadID: The upload ID of the multipart upload
//   - partNumbers: Slice of part numbers in the order they were uploaded
//   - etags: Slice of ETags for each part, must correspond to partNumbers
//
// Returns an error if the completion fails.
//
// Example:
//
//	err := minioClient.CompleteMultipartUpload(
//	    ctx,
//	    "uploads/myfile.zip",
//	    uploadID,
//	    []int{1, 2, 3},
//	    []string{"etag1", "etag2", "etag3"},
//	)
func (m *MinioClient) CompleteMultipartUpload(ctx context.Context, bucket, objectKey, uploadID string, partNumbers []int, etags []string) error {
	if len(partNumbers) == 0 || len(etags) == 0 {
		return fmt.Errorf("cannot complete multipart upload with no parts")
	}

	if len(partNumbers) != len(etags) {
		return fmt.Errorf("mismatched part numbers and etags: got %d part numbers and %d etags", len(partNumbers), len(etags))
	}

	// Create complete parts and ensure they're in order
	type partInfo struct {
		idx        int
		partNumber int
		etag       string
	}

	parts := make([]partInfo, len(partNumbers))
	for i := range partNumbers {
		parts[i] = partInfo{idx: i, partNumber: partNumbers[i], etag: etags[i]}
	}

	// Sort by part number
	sort.Slice(parts, func(i, j int) bool {
		return parts[i].partNumber < parts[j].partNumber
	})

	// Convert to minio.CompletePart
	completeParts := make([]minio.CompletePart, len(parts))
	for i, part := range parts {
		completeParts[i] = minio.CompletePart{
			PartNumber: part.partNumber,
			ETag:       part.etag,
		}
	}

	// Complete the multipart upload
	core := m.coreClient.Load()
	if core == nil {
		return ErrConnectionFailed
	}

	_, err := core.CompleteMultipartUpload(ctx, bucket, objectKey, uploadID, completeParts, minio.PutObjectOptions{})
	if err != nil {
		return fmt.Errorf("failed to complete multipart upload: %w", err)
	}

	return nil
}

// ListIncompleteUploads lists all incomplete multipart uploads for cleanup.
// This method retrieves information about multipart uploads that were started
// but never completed or aborted.
//
// Parameters:
//   - ctx: Context for the operation
//   - prefix: Optional prefix to filter objects by key
//
// Returns:
//   - []minio.ObjectMultipartInfo: Information about incomplete uploads
//   - error: Any error that occurred during the listing
//
// Example:
//
//	uploads, err := minioClient.ListIncompleteUploads(ctx, "uploads/")
//	if err == nil {
//	    for _, upload := range uploads {
//	        fmt.Printf("Incomplete upload: %s, started: %v\n", upload.Key, upload.Initiated)
//	    }
//	}
func (m *MinioClient) ListIncompleteUploads(ctx context.Context, bucket, prefix string) ([]minio.ObjectMultipartInfo, error) {
	var incompleteUploads []minio.ObjectMultipartInfo

	// List incomplete uploads
	core := m.coreClient.Load()
	if core == nil {
		return nil, ErrConnectionFailed
	}

	objectCh := core.ListIncompleteUploads(ctx, bucket, prefix, true)

	for object := range objectCh {
		if object.Err != nil {
			return nil, fmt.Errorf("error listing incomplete uploads: %w", object.Err)
		}
		incompleteUploads = append(incompleteUploads, object)
	}

	return incompleteUploads, nil
}

// CleanupIncompleteUploads aborts any incomplete uploads older than the given duration.
// This method helps maintain storage hygiene by removing abandoned upload sessions.
//
// Parameters:
//   - ctx: Context for the operation
//   - prefix: Optional prefix to filter objects by key
//   - olderThan: Only abort uploads older than this duration
//
// Return an error if the cleanup operation fails.
//
// Example:
//
//	// Abort all incomplete uploads in the "uploads/" prefix that are older than 24 hours
//	err := minioClient.CleanupIncompleteUploads(ctx, "uploads/", 24*time.Hour)
func (m *MinioClient) CleanupIncompleteUploads(ctx context.Context, bucket, prefix string, olderThan time.Duration) error {
	uploads, err := m.ListIncompleteUploads(ctx, bucket, prefix)
	if err != nil {
		return err
	}

	cutoffTime := time.Now().Add(-olderThan)

	for _, upload := range uploads {
		// Check if upload is older than cutoff
		if upload.Initiated.Before(cutoffTime) {
			err := m.AbortMultipartUpload(ctx, bucket, upload.Key, upload.UploadID)
			if err != nil {
				return fmt.Errorf("failed to abort multipart upload: %w", err)
			}
		}
	}

	return nil
}

// PreSignedHeadObject generates a pre-signed URL for HeadObject operations.
// This method creates a temporary URL that allows checking object metadata
// without downloading the object itself.
//
// Parameters:
//   - ctx: Context for the operation
//   - objectKey: Path and name of the object in the bucket
//
// Returns:
//   - string: The presigned URL for the HEAD operation
//   - error: Any error that occurred during URL generation
//
// Example:
//
//	url, err := minioClient.PreSignedHeadObject(ctx, "documents/report.pdf")
//	if err == nil {
//	    fmt.Printf("Use this URL to check if the object exists: %s\n", url)
//	}
func (m *MinioClient) PreSignedHeadObject(ctx context.Context, bucket, objectKey string) (string, error) {
	start := time.Now()
	c := m.client.Load()
	if c == nil {
		m.observeOperation("presigned_head", bucket, objectKey, time.Since(start), ErrConnectionFailed, 0, nil)
		return "", ErrConnectionFailed
	}

	presignedUrl, err := c.PresignedHeadObject(ctx, bucket, objectKey, m.cfg.PresignedConfig.ExpiryDuration, nil)
	if err != nil {
		m.observeOperation("presigned_head", bucket, objectKey, time.Since(start), err, 0, nil)
		return "", err
	}

	var result string
	if m.cfg.PresignedConfig.BaseURL != "" {
		result, err = urlGenerator(presignedUrl, m.cfg.PresignedConfig.BaseURL)
	} else {
		result = presignedUrl.String()
	}
	m.observeOperation("presigned_head", bucket, objectKey, time.Since(start), err, 0, nil)
	return result, err
}

// PreSignedPut generates a pre-signed URL for PutObject operations.
// This method creates a temporary URL that allows uploading an object
// without additional authentication.
//
// Parameters:
//   - ctx: Context for the operation
//   - objectKey: Path and name of the object in the bucket
//
// Returns:
//   - string: The presigned URL for uploading the object
//   - error: Any error that occurred during URL generation
//
// Example:
//
//	url, err := minioClient.PreSignedPut(ctx, "documents/report.pdf")
//	if err == nil {
//	    fmt.Printf("Upload link: %s\n", url)
//	}
func (m *MinioClient) PreSignedPut(ctx context.Context, bucket, objectKey string) (string, error) {
	start := time.Now()
	c := m.client.Load()
	if c == nil {
		m.observeOperation("presigned_put", bucket, objectKey, time.Since(start), ErrConnectionFailed, 0, nil)
		return "", ErrConnectionFailed
	}

	presignedUrl, err := c.PresignedPutObject(ctx, bucket, objectKey, m.cfg.PresignedConfig.ExpiryDuration)
	if err != nil {
		m.observeOperation("presigned_put", bucket, objectKey, time.Since(start), err, 0, nil)
		return "", err
	}

	var result string
	if m.cfg.PresignedConfig.BaseURL != "" {
		result, err = urlGenerator(presignedUrl, m.cfg.PresignedConfig.BaseURL)
	} else {
		result = presignedUrl.String()
	}
	m.observeOperation("presigned_put", bucket, objectKey, time.Since(start), err, 0, nil)
	return result, err
}
